{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "block_size = 64\n",
    "batch_size = 128\n",
    "max_iters = 3000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 50\n",
    "n_embd = 384\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('romeo_juliet.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([128, 64])\n",
      "tensor([[59,  2, 60,  ..., 73, 10,  2],\n",
      "        [74,  2, 74,  ..., 38, 37, 30],\n",
      "        [72,  2, 66,  ..., 72, 59, 55],\n",
      "        ...,\n",
      "        [68, 74, 72,  ..., 58, 67, 63],\n",
      "        [ 2, 67, 75,  ..., 77, 62, 59],\n",
      "        [ 2, 72, 59,  ..., 58, 63, 73]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[ 2, 60, 66,  ..., 10,  2, 55],\n",
      "        [ 2, 74, 62,  ..., 37, 30, 45],\n",
      "        [ 2, 66, 69,  ..., 59, 55, 58],\n",
      "        ...,\n",
      "        [74, 72, 55,  ..., 67, 63, 74],\n",
      "        [67, 75, 57,  ..., 62, 59, 68],\n",
      "        [72, 59, 74,  ..., 63, 73, 74]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Generate random indices within a valid range\n",
    "    ix = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "\n",
    "    # Debug: Print the generated indices\n",
    "    #print(f\"Generated indices (ix): {ix}\")\n",
    "\n",
    "    # Create input (x) and target (y) sequences based on the indices\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    # Debug: Print the shapes of x and y\n",
    "    #print(f\"x shape: {x.shape}, y shape: {y.shape}\")\n",
    "\n",
    "    # Move x and y to the correct device (GPU or CPU)\n",
    "    try:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when transferring data to device: {e}\")\n",
    "        raise e  # Re-raise the exception for further investigation\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([90]) target is tensor(1)\n",
      "when input is tensor([90,  1]) target is tensor(33)\n",
      "when input is tensor([90,  1, 33]) target is tensor(26)\n",
      "when input is tensor([90,  1, 33, 26]) target is tensor(38)\n",
      "when input is tensor([90,  1, 33, 26, 38]) target is tensor(37)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37]) target is tensor(30)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30]) target is tensor(45)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45]) target is tensor(12)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12]) target is tensor(1)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1]) target is tensor(31)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31]) target is tensor(69)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69]) target is tensor(72)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2]) target is tensor(63)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63]) target is tensor(60)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2]) target is tensor(74)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74]) target is tensor(62)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62]) target is tensor(59)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2]) target is tensor(73)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73]) target is tensor(75)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75]) target is tensor(68)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2]) target is tensor(56)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56]) target is tensor(72)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72]) target is tensor(59)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59]) target is tensor(59)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59]) target is tensor(58)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2]) target is tensor(67)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67]) target is tensor(55)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55]) target is tensor(61)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61]) target is tensor(61)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61]) target is tensor(69)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69]) target is tensor(74)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74]) target is tensor(73)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2]) target is tensor(63)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63]) target is tensor(68)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2]) target is tensor(55)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2]) target is tensor(58)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58]) target is tensor(59)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59]) target is tensor(55)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55]) target is tensor(58)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2]) target is tensor(58)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58]) target is tensor(69)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69]) target is tensor(61)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61]) target is tensor(10)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2]) target is tensor(56)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56]) target is tensor(59)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59]) target is tensor(63)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63]) target is tensor(68)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68]) target is tensor(61)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61,  2]) target is tensor(55)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61,  2, 55]) target is tensor(2)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61,  2, 55,  2]) target is tensor(61)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61,  2, 55,  2, 61]) target is tensor(69)\n",
      "when input is tensor([90,  1, 33, 26, 38, 37, 30, 45, 12,  1, 31, 69, 72,  2, 63, 60,  2, 74,\n",
      "        62, 59,  2, 73, 75, 68,  2, 56, 72, 59, 59, 58,  2, 67, 55, 61, 61, 69,\n",
      "        74, 73,  2, 63, 68,  2, 55,  2, 58, 59, 55, 58,  2, 58, 69, 61, 10,  2,\n",
      "        56, 59, 63, 68, 61,  2, 55,  2, 61, 69]) target is tensor(69)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is', context, 'target is', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model parameters...\n",
      "loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    \"\"\" def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "        \"\"\"\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "    \n",
    "        # Check if any index is out of bounds for the token embedding (should be between 0 and vocab_size-1)\n",
    "        if index.max() >= vocab_size or index.min() < 0:\n",
    "            print(f\"Warning: Index out of range in 'index' tensor!\")\n",
    "            print(f\"Max index: {index.max().item()}, Min index: {index.min().item()}\")\n",
    "    \n",
    "        # Token embeddings\n",
    "        tok_emb = self.token_embedding_table(index)  # (B,T,C)\n",
    "    \n",
    "        # Position embeddings\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # (T,C)\n",
    "    \n",
    "        # Add token and position embeddings\n",
    "        x = tok_emb + pos_emb  # (B,T,C)\n",
    "        \n",
    "        # Pass through transformer blocks\n",
    "        x = self.blocks(x)  # (B,T,C)\n",
    "    \n",
    "        # Final layer normalization\n",
    "        x = self.ln_f(x)  # (B,T,C)\n",
    "    \n",
    "        # Compute logits for the language model head\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "    \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Compute loss if targets are provided\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            #print(f\"Logits shape for loss: {logits.shape}\")\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "    \n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "print('loading model parameters...')\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print('loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.610, val loss: 4.630\n",
      "step: 50, train loss: 2.548, val loss: 2.540\n",
      "step: 100, train loss: 2.380, val loss: 2.351\n",
      "step: 150, train loss: 2.170, val loss: 2.140\n",
      "step: 200, train loss: 2.032, val loss: 2.007\n",
      "step: 250, train loss: 1.918, val loss: 1.897\n",
      "step: 300, train loss: 1.842, val loss: 1.825\n",
      "step: 350, train loss: 1.778, val loss: 1.759\n",
      "step: 400, train loss: 1.736, val loss: 1.721\n",
      "step: 450, train loss: 1.677, val loss: 1.669\n",
      "step: 500, train loss: 1.649, val loss: 1.656\n",
      "step: 550, train loss: 1.611, val loss: 1.618\n",
      "step: 600, train loss: 1.594, val loss: 1.604\n",
      "step: 650, train loss: 1.550, val loss: 1.569\n",
      "step: 700, train loss: 1.533, val loss: 1.558\n",
      "step: 750, train loss: 1.512, val loss: 1.525\n",
      "step: 800, train loss: 1.491, val loss: 1.516\n",
      "step: 850, train loss: 1.471, val loss: 1.506\n",
      "step: 900, train loss: 1.452, val loss: 1.494\n",
      "step: 950, train loss: 1.441, val loss: 1.489\n",
      "step: 1000, train loss: 1.424, val loss: 1.475\n",
      "step: 1050, train loss: 1.420, val loss: 1.464\n",
      "step: 1100, train loss: 1.399, val loss: 1.460\n",
      "step: 1150, train loss: 1.390, val loss: 1.444\n",
      "step: 1200, train loss: 1.377, val loss: 1.443\n",
      "step: 1250, train loss: 1.370, val loss: 1.443\n",
      "step: 1300, train loss: 1.365, val loss: 1.437\n",
      "step: 1350, train loss: 1.346, val loss: 1.430\n",
      "step: 1400, train loss: 1.338, val loss: 1.420\n",
      "step: 1450, train loss: 1.328, val loss: 1.419\n",
      "step: 1500, train loss: 1.316, val loss: 1.419\n",
      "step: 1550, train loss: 1.312, val loss: 1.417\n",
      "step: 1600, train loss: 1.300, val loss: 1.409\n",
      "step: 1650, train loss: 1.289, val loss: 1.397\n",
      "step: 1700, train loss: 1.284, val loss: 1.397\n",
      "step: 1750, train loss: 1.279, val loss: 1.412\n",
      "step: 1800, train loss: 1.268, val loss: 1.390\n",
      "step: 1850, train loss: 1.263, val loss: 1.396\n",
      "step: 1900, train loss: 1.253, val loss: 1.391\n",
      "step: 1950, train loss: 1.242, val loss: 1.391\n",
      "step: 2000, train loss: 1.244, val loss: 1.387\n",
      "step: 2050, train loss: 1.232, val loss: 1.390\n",
      "step: 2100, train loss: 1.222, val loss: 1.386\n",
      "step: 2150, train loss: 1.223, val loss: 1.387\n",
      "step: 2200, train loss: 1.215, val loss: 1.390\n",
      "step: 2250, train loss: 1.206, val loss: 1.387\n",
      "step: 2300, train loss: 1.200, val loss: 1.394\n",
      "step: 2350, train loss: 1.190, val loss: 1.388\n",
      "step: 2400, train loss: 1.183, val loss: 1.387\n",
      "step: 2450, train loss: 1.179, val loss: 1.376\n",
      "step: 2500, train loss: 1.174, val loss: 1.384\n",
      "step: 2550, train loss: 1.169, val loss: 1.401\n",
      "step: 2600, train loss: 1.158, val loss: 1.397\n",
      "step: 2650, train loss: 1.154, val loss: 1.392\n",
      "step: 2700, train loss: 1.148, val loss: 1.379\n",
      "step: 2750, train loss: 1.141, val loss: 1.391\n",
      "step: 2800, train loss: 1.135, val loss: 1.389\n",
      "step: 2850, train loss: 1.132, val loss: 1.395\n",
      "step: 2900, train loss: 1.126, val loss: 1.397\n",
      "step: 2950, train loss: 1.117, val loss: 1.393\n",
      "1.1810663938522339\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "\n",
    "with open('model-01.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tyour Gonzalo; and she faces all itself\n",
      "To line in’s ganer away, and for all one to o’erher\n",
      "Of heaven, from his power faith art through well be asleep,\n",
      "And help that lives to sudden their senses are poor, foul that go streen are\n",
      "they I find: thou’dst empt here pawn\n",
      "Indion mortal are: and the fice of love o’er-happen cruelly\n",
      "Him to hears not a round: they were well go a pleasure.\n",
      "\n",
      "_Ste._ Thy king's a king of sister, bore, if he is the which flies, sir?\n",
      "\n",
      "_Pros._ By, nympher, if you fancience that s\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-llm-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
